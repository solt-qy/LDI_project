{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a2a9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7afe82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>package_hash</th>\n",
       "      <th>manual_tag</th>\n",
       "      <th>tag_set</th>\n",
       "      <th>category_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-02-19 19_39_18.wav</td>\n",
       "      <td>635_cnnmodel_20190220_verification_package</td>\n",
       "      <td>ba-do</td>\n",
       "      <td>{do, ba}</td>\n",
       "      <td>{animal_dogs, background}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-02-06 13_14_24.wav</td>\n",
       "      <td>635_cnnmodel_20190220_verification_package</td>\n",
       "      <td>ta-do</td>\n",
       "      <td>{do, ta}</td>\n",
       "      <td>{animal_dogs, human_voice}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-02-19 19_46_53.wav</td>\n",
       "      <td>635_cnnmodel_20190220_verification_package</td>\n",
       "      <td>ba-do</td>\n",
       "      <td>{do, ba}</td>\n",
       "      <td>{animal_dogs, background}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-02-17 19_23_04.wav</td>\n",
       "      <td>635_cnnmodel_20190220_verification_package</td>\n",
       "      <td>cr-do</td>\n",
       "      <td>{cr, do}</td>\n",
       "      <td>{animal_dogs, animal_insects}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-02-19 19_03_00.wav</td>\n",
       "      <td>635_cnnmodel_20190220_verification_package</td>\n",
       "      <td>wi-ba</td>\n",
       "      <td>{wi, ba}</td>\n",
       "      <td>{nature_wind, background}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename                                package_hash  \\\n",
       "0  2019-02-19 19_39_18.wav  635_cnnmodel_20190220_verification_package   \n",
       "1  2019-02-06 13_14_24.wav  635_cnnmodel_20190220_verification_package   \n",
       "2  2019-02-19 19_46_53.wav  635_cnnmodel_20190220_verification_package   \n",
       "3  2019-02-17 19_23_04.wav  635_cnnmodel_20190220_verification_package   \n",
       "4  2019-02-19 19_03_00.wav  635_cnnmodel_20190220_verification_package   \n",
       "\n",
       "  manual_tag   tag_set                   category_set  \n",
       "0      ba-do  {do, ba}      {animal_dogs, background}  \n",
       "1      ta-do  {do, ta}     {animal_dogs, human_voice}  \n",
       "2      ba-do  {do, ba}      {animal_dogs, background}  \n",
       "3      cr-do  {cr, do}  {animal_dogs, animal_insects}  \n",
       "4      wi-ba  {wi, ba}      {nature_wind, background}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set path to local model directory\n",
    "model_root_dir = pathlib.Path('../../../models')\n",
    "model_names = ['SMBCE', 'SMF1', 'LGBCE', 'LGF1', 'BDBCE']\n",
    "\n",
    "# considered categories\n",
    "small_cat = ['animal_dogs', 'animal_birds', 'human_voice', 'transport_car', 'mechanical', 'music']\n",
    "large_cat = [\"animal_dogs\", \"animal_insects\", \"animal_birds\", \"animal_cockatoo\", \"animal_poultry\",  \"background\", \"human_voice\", \"indeterminate\", \"mechanical\", \"mechanical_construction\", \"mechanical_impulsive\", \"mechanical_plant\", \"nature_wind\", \"signals_horn\", \"signals_siren\", \"transport_car\", 'music']\n",
    "binary_dogs = ['animal_dogs']\n",
    "model_categories_lookup = {'SMBCE': small_cat, 'SMF1': small_cat, 'LGBCE': large_cat, 'LGF1': large_cat, 'BDBCE': binary_dogs}\n",
    "\n",
    "# Read manifest data from path\n",
    "# set your path here\n",
    "# alternatively, read in the csv and assign categories yourself (see 01_dataset_curation.ipynb)\n",
    "data_root = pathlib.Path('/Volumes/Clavius/documents/Documents/Employment/NoiseNet/Development/tag_data/processed') \n",
    "manifest_path = data_root/'01_manifest.pkl'\n",
    "\n",
    "# read the manifest in\n",
    "manifest = pd.read_pickle(manifest_path)\n",
    "manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04d7cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class OneVsOtherBinarizer(object):\n",
    "    # simple dummy class for a fit for purpose one vs others binariser\n",
    "    # keep a similar api to other binarisers used to avoid modifying code down the track\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        pass\n",
    "    def fit(self, the_one):\n",
    "        self.the_one = the_one\n",
    "        self.the_others = 'not_'+the_one\n",
    "        self.classes_ = np.array([self.the_others, the_one])\n",
    "        return self\n",
    "    def transform(self, data):\n",
    "        _bin = np.array([self.the_one in d for d in data])\n",
    "        _bin = _bin.astype(np.int32)\n",
    "        return _bin\n",
    "\n",
    "\n",
    "def get_category_encoder(categories):\n",
    "    # return an appropriate encoder for the classification problem\n",
    "    # again, quite fit for purpose\n",
    "    if len(categories) == 1:\n",
    "        return OneVsOtherBinarizer().fit(categories[0])\n",
    "    else:\n",
    "        return MultiLabelBinarizer().fit([categories])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadadf29",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c40ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These spectrogram settings look pretty good from a domain perspective.\n",
    "# Trying a little bit higher \"resolution\" than previously\n",
    "mel_settings = {'fmax': 8000, 'power': 2, 'n_mels' :128, 'n_fft':2048, 'hop_length':512}\n",
    "fs_nom = 16000 # Nominal sampling rate. Most files should be this rate, but if not, they will be resampled\n",
    "shape_nom = (128,126) # nominal spectrogram shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c4ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn\n",
    "\n",
    "def force_array_shape(x, force_shape):\n",
    "    \"\"\"Forces a numpy array to a specific shape by filling with zeros, or truncating\"\"\"\n",
    "    pad_widths = []\n",
    "    for ax, ax_length in enumerate(force_shape):\n",
    "        if x.shape[ax] >= ax_length:\n",
    "            x = x.take(indices=range(0,ax_length), axis=ax)\n",
    "        pad_widths.append((0,ax_length-x.shape[ax]))\n",
    "    x = np.pad(x, pad_widths)\n",
    "    return x\n",
    "\n",
    "def get_mels(filepath='', data=[], fs=None, force_shape=None):\n",
    "    if filepath:\n",
    "        data, fs = librosa.load(filepath, sr=fs)\n",
    "        if fs != fs_nom:\n",
    "            print(filepath)\n",
    "    else:\n",
    "        assert (len(data>0) and fs >0), 'Must provide either a filename, or array of data and sample rate'\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=data, sr = fs, **mel_settings)\n",
    "    \n",
    "    if force_shape and S.shape != force_shape:\n",
    "        \n",
    "        S = force_array_shape(S, force_shape)\n",
    "            \n",
    "    return S, fs\n",
    " \n",
    "def load_mels(filepath, force_create=False, save=True):\n",
    "    mel_path = filepath.with_suffix('.npy')\n",
    "    \n",
    "    if mel_path.is_file() and not force_create:\n",
    "        #print('Loading {}'.format(mel_path))\n",
    "        mels = np.load(mel_path)\n",
    "    else:\n",
    "        #print('Generating from {}'.format(filepath))\n",
    "        mels, _ = get_mels(filepath, fs=fs_nom, force_shape = shape_nom)\n",
    "        if save:\n",
    "            #print('Saving {}'.format(mel_path))\n",
    "            np.save(mel_path, mels)\n",
    "    \n",
    "    return mels\n",
    "\n",
    "def feature_preprocessing(mel):\n",
    "    # convert to db and normalise\n",
    "    power = librosa.core.power_to_db(mel, ref=np.max)\n",
    "    power = power - np.mean(power)\n",
    "    power = power / (np.std(power))\n",
    "    return power[:, :, None]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af842327",
   "metadata": {},
   "source": [
    "# Model Evaluation Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d9151df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "def select_evaluation_folds(df, n_folds=10):\n",
    "    # get a random selection of package_hash names for fold selection\n",
    "    folds = df.groupby('package_hash')\n",
    "    np.random.seed(0)\n",
    "    selections = np.random.choice(list(folds.groups.keys()), n_folds, replace=False)\n",
    "    \n",
    "    return [folds.get_group(g) for g in selections]\n",
    "\n",
    "def exact_count(y_true, y_pred):\n",
    "    # metric to compute the exact match ratio\n",
    "    # this portion counts 0/1 whether prediction exactly matches target.\n",
    "    # use ec.numpy().mean() to get the ratio\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    predictions = tf.cast(tf.greater_equal(y_pred, 0.5), tf.float32)\n",
    "    pred_match = tf.equal(predictions, tf.round(y_true))\n",
    "    exact_count = tf.math.reduce_min(tf.cast(pred_match, tf.float32), axis=1)\n",
    "    return exact_count\n",
    "\n",
    "\n",
    "def classification_report_to_df(report):\n",
    "    # hack to get around binary classifiers having a non-nested accuracy entry\n",
    "    # nest it\n",
    "    if report.get('accuracy'):\n",
    "        report['accuracy'] = {'accuracy':report['accuracy']}\n",
    "    df = pd.concat({\n",
    "        k: pd.DataFrame.from_dict(v, 'index') for k, v in report.items()\n",
    "    }, \n",
    "    axis=0)\n",
    "\n",
    "    return df\n",
    "def evaluate_fold(fold,target_names, model):\n",
    "    # predict all samples in a fold, and return a dataframe structure corresponding to the results, for later processing\n",
    "    \n",
    "    # get the audio features\n",
    "    fold['features'] = fold.apply(lambda x: data_root/x['package_hash']/x['filename'], axis=1).apply(lambda x: feature_preprocessing(load_mels(x, force_create=False, save=True)))\n",
    "\n",
    "    # sometimes nan's leak in, from bad source data remove them\n",
    "    fold = fold[~fold['features'].apply(lambda x: np.any(np.isnan(x.flatten())))]\n",
    "    \n",
    "    # prepare for prediction\n",
    "    X = np.stack(fold['features'].values)\n",
    "    y = category_encoder.transform(fold['category_set'].values)\n",
    "    y_pred=model.predict(X)\n",
    "\n",
    "    # get the classification report as a dictionary\n",
    "    cr = classification_report(y, (y_pred>=0.5).astype(y.dtype), target_names=target_names, output_dict=True)\n",
    "    # hack in the EMR into the results structure\n",
    "    cr['EMR'] = {'EMR': exact_count(y, y_pred).numpy().mean()}\n",
    "    # convert to a dataframe\n",
    "    cr = classification_report_to_df(cr)\n",
    "    # prepend the fold name as the 0th index level\n",
    "    cr = pd.concat({fold['package_hash'].values[0]: cr}, names=['package_hash'])\n",
    "    return cr\n",
    "\n",
    "def evaluate_model(df, model, target_names, k_folds=10):\n",
    "    # perform an evaluation of the model across k_folds \n",
    "    selections = select_evaluation_folds(df, n_folds)\n",
    "    \n",
    "    results = []\n",
    "    for fold in selections:\n",
    "        cr = evaluate_fold(fold, target_names, model)\n",
    "        results.append(cr)\n",
    "    return pd.concat(results)\n",
    "\n",
    "def plot_model_evaluation(results, evaluations=[('EMR', 'EMR'), ('macro avg', 'f1-score'), ('animal_dogs', 'f1-score')], *args, **kwargs):\n",
    "    # plot the distribution of metric evaluations across all folds. \n",
    "    # save image to disk\n",
    "    plt.figure(figsize=(12,10), dpi=200)\n",
    "    ax = plt.gca()\n",
    "    for (lev_1, lev_2) in evaluations:\n",
    "        # plot the histogram for the particular evaluation into the axis\n",
    "        results.loc[:,lev_1, lev_2].plot.hist(ax=ax,bins=np.linspace(0,1,30), alpha=0.5)\n",
    "    # format and plot\n",
    "    plt.title(kwargs.get('title', ''))\n",
    "    plt.ylabel('Count')\n",
    "    plt.xlabel('Metric score')\n",
    "    plt.legend([lev_1 if lev_1==lev_2 else f'{lev_1} {lev_2}' for lev_1, lev_2 in evaluations])\n",
    "    plt.savefig('{}.png'.format(kwargs.get('title')))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baecc7b7",
   "metadata": {},
   "source": [
    "# Evaluate the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4331b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BDBCE on k=50 folds\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "# a few annoying warnings are spit out for various reasons\n",
    "# turn them off for now.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "for model_name in model_names:\n",
    "    k=50\n",
    "    print(f'Evaluating {model_name} on k={k} folds')\n",
    "    model = keras.models.load_model((model_root_dir/model_name).with_suffix('.hdf5'), compile=False)\n",
    "    category_encoder = get_category_encoder(model_categories_lookup[model_name])\n",
    "\n",
    "    results = evaluate_model(manifest,model,category_encoder.classes_,k)\n",
    "    plot_model_evaluation(results,evaluations = [('macro avg', 'f1-score'), ('animal_dogs', 'f1-score')], title=f'Distribution of metrics for Model {model_name}: k={k} folds')\n",
    "\n",
    "warnings.filterwarnings(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28452c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d26ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979b0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075368ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811a439b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1678af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea8f462",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8c60b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3658fc01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d729b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d618dcec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319b08dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3d08e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02b3f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84593e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
