{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6a2a9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03012c7",
   "metadata": {},
   "source": [
    "## DNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9f9143e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional LSTM as introduced in the report\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras import regularizers\n",
    "\n",
    "def resnet_ldnn(num_label):\n",
    "    model = Sequential()\n",
    "    model.add(keras.applications.resnet50.ResNet50(include_top=False, input_shape=(128, 126, 1), \n",
    "                                                   weights=None, classes=None, pooling='average'))\n",
    "    model.add(Permute((2, 1, 3)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(64, dropout=0.25, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.25))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_label, kernel_regularizer=regularizers.l2(0.01), activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadadf29",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3d1278e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import ast\n",
    "\n",
    "# Read data from path\n",
    "data_root = pathlib.Path('classical_set\\\\')\n",
    "# manifest will be a pandas dataframe that contains information of the audio data and its label\n",
    "manifest = pd.read_csv(\"classical_set\\\\01_manifest.csv\")\n",
    "manifest['tag_set'] = manifest['tag_set'].apply(ast.literal_eval)\n",
    "manifest['category_set'] = manifest['category_set'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7fc503a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "final_categories = ['animal_dogs', 'animal_birds', 'human_voice', 'transport_car','music','mechanical']\n",
    "category_encoder = MultiLabelBinarizer().fit([final_categories])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "75f2a4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>package_hash</th>\n",
       "      <th>manual_tag</th>\n",
       "      <th>tag_set</th>\n",
       "      <th>category_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animal_birds</td>\n",
       "      <td>2019-03-26 18_43_23.wav</td>\n",
       "      <td>sbfg</td>\n",
       "      <td>bi</td>\n",
       "      <td>{bi}</td>\n",
       "      <td>{animal_birds}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>animal_birds</td>\n",
       "      <td>2019-08-21 09_45_45.wav</td>\n",
       "      <td>slhg_1</td>\n",
       "      <td>bi</td>\n",
       "      <td>{bi}</td>\n",
       "      <td>{animal_birds}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>animal_birds</td>\n",
       "      <td>2019-05-18 12_18_54.wav</td>\n",
       "      <td>nbwo_1</td>\n",
       "      <td>bi</td>\n",
       "      <td>{bi}</td>\n",
       "      <td>{animal_birds}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>animal_birds</td>\n",
       "      <td>2019-09-18 12_31_41.wav</td>\n",
       "      <td>qhxt</td>\n",
       "      <td>bi</td>\n",
       "      <td>{bi}</td>\n",
       "      <td>{animal_birds}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>animal_birds</td>\n",
       "      <td>2019-08-23 11_57_58.wav</td>\n",
       "      <td>slhg_2</td>\n",
       "      <td>bi</td>\n",
       "      <td>{bi}</td>\n",
       "      <td>{animal_birds}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>transport_car</td>\n",
       "      <td>2019-10-10 19_22_47.wav</td>\n",
       "      <td>fudn</td>\n",
       "      <td>ca</td>\n",
       "      <td>{ca}</td>\n",
       "      <td>{transport_car}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>transport_car</td>\n",
       "      <td>2019-08-24 20_19_55.wav</td>\n",
       "      <td>rlzn</td>\n",
       "      <td>ca</td>\n",
       "      <td>{ca}</td>\n",
       "      <td>{transport_car}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>transport_car</td>\n",
       "      <td>2019-06-28 19_34_03.wav</td>\n",
       "      <td>tstr</td>\n",
       "      <td>ca</td>\n",
       "      <td>{ca}</td>\n",
       "      <td>{transport_car}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>transport_car</td>\n",
       "      <td>2021-06-12T02_02_33+0930.wav</td>\n",
       "      <td>flso</td>\n",
       "      <td>ca</td>\n",
       "      <td>{ca}</td>\n",
       "      <td>{transport_car}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>transport_car</td>\n",
       "      <td>2021-07-20T04_35_26+1000.wav</td>\n",
       "      <td>pgdk</td>\n",
       "      <td>ca</td>\n",
       "      <td>{ca}</td>\n",
       "      <td>{transport_car}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          category                      filename package_hash manual_tag  \\\n",
       "0     animal_birds       2019-03-26 18_43_23.wav         sbfg         bi   \n",
       "1     animal_birds       2019-08-21 09_45_45.wav       slhg_1         bi   \n",
       "2     animal_birds       2019-05-18 12_18_54.wav       nbwo_1         bi   \n",
       "3     animal_birds       2019-09-18 12_31_41.wav         qhxt         bi   \n",
       "4     animal_birds       2019-08-23 11_57_58.wav       slhg_2         bi   \n",
       "..             ...                           ...          ...        ...   \n",
       "295  transport_car       2019-10-10 19_22_47.wav         fudn         ca   \n",
       "296  transport_car       2019-08-24 20_19_55.wav         rlzn         ca   \n",
       "297  transport_car       2019-06-28 19_34_03.wav         tstr         ca   \n",
       "298  transport_car  2021-06-12T02_02_33+0930.wav         flso         ca   \n",
       "299  transport_car  2021-07-20T04_35_26+1000.wav         pgdk         ca   \n",
       "\n",
       "    tag_set     category_set  \n",
       "0      {bi}   {animal_birds}  \n",
       "1      {bi}   {animal_birds}  \n",
       "2      {bi}   {animal_birds}  \n",
       "3      {bi}   {animal_birds}  \n",
       "4      {bi}   {animal_birds}  \n",
       "..      ...              ...  \n",
       "295    {ca}  {transport_car}  \n",
       "296    {ca}  {transport_car}  \n",
       "297    {ca}  {transport_car}  \n",
       "298    {ca}  {transport_car}  \n",
       "299    {ca}  {transport_car}  \n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d6000b7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# storing audio features into array\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import numpy as np\n",
    "# convert cateogry into intger labels\n",
    "manifest.category = pd.Categorical(manifest.category)\n",
    "manifest[\"label\"] = manifest.category.cat.codes\n",
    "# Total 300 recordings\n",
    "num = 300\n",
    "train_set = np.zeros((len(final_categories), 50, 126, 20))\n",
    "for i in range(num):\n",
    "    x = manifest.iloc[i]\n",
    "    # load the auio path and read the audio with sampling frequency as 16000 Hz\n",
    "    sig, fs = librosa.load(data_root/x['package_hash']/x['filename'], sr=16000)\n",
    "    sig = sig / sig.max()\n",
    "    # each category contains 50 recordings \n",
    "    # i//50 is the corresponding category of the audio\n",
    "    # i%50 is the order of the recording in the 50 recrodings for the category\n",
    "    train_set[i//50, i%50] = librosa.feature.mfcc(y=sig, sr=fs).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc16768",
   "metadata": {},
   "source": [
    "## Classical ML method - HMM-GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "9d070489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45 for training, 5 for testing\n",
    "num_train = 45\n",
    "num_test = 50 - num_train\n",
    "test_set = np.zeros((num_test*6, 126, 20))\n",
    "test_set_label = np.zeros((num_test*6, 1))\n",
    "for i in range(num_test*6):\n",
    "    test_set_label[i] = i//num_test\n",
    "hmm_classifier_lists = []\n",
    "# for each category train a classifier using the 45 audio data in the category\n",
    "for j in range(len(final_categories)):\n",
    "    current_train_set = np.concatenate(train_set[j][:num_train])\n",
    "    test_set[j*num_test :(j+1)*num_test] = train_set[j][num_train:]\n",
    "    lengths = [126 for i in range(num_train)]\n",
    "    hmm_classifier_lists.append(hmm.GaussianHMM(n_components=7,n_iter=100,covariance_type='full'))\n",
    "    hmm_classifier_lists[-1].fit(current_train_set, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5a29191f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now testing for category animal_dogs\n",
      "correct animal_dogs\n",
      "correct animal_dogs\n",
      "correct animal_dogs\n",
      "wrong animal_dogs classified as animal_birds \n",
      "wrong animal_dogs classified as animal_birds \n",
      "\n",
      "Now testing for category animal_birds\n",
      "correct animal_birds\n",
      "wrong animal_birds classified as human_voice \n",
      "correct animal_birds\n",
      "correct animal_birds\n",
      "correct animal_birds\n",
      "\n",
      "Now testing for category human_voice\n",
      "correct human_voice\n",
      "wrong human_voice classified as music \n",
      "correct human_voice\n",
      "wrong human_voice classified as music \n",
      "correct human_voice\n",
      "\n",
      "Now testing for category transport_car\n",
      "wrong transport_car classified as human_voice \n",
      "correct transport_car\n",
      "wrong transport_car classified as music \n",
      "wrong transport_car classified as human_voice \n",
      "wrong transport_car classified as animal_birds \n",
      "\n",
      "Now testing for category music\n",
      "correct music\n",
      "correct music\n",
      "wrong music classified as human_voice \n",
      "correct music\n",
      "correct music\n",
      "\n",
      "Now testing for category mechanical\n",
      "correct mechanical\n",
      "correct mechanical\n",
      "wrong mechanical classified as animal_birds \n",
      "wrong mechanical classified as music \n",
      "wrong mechanical classified as transport_car \n",
      "The prediction accuracy on test set is 0.57\n"
     ]
    }
   ],
   "source": [
    "total_test_data= num_test*6\n",
    "num_correct = 0\n",
    "true_label = -1\n",
    "# use maximum likelihood to determine the corresponding category\n",
    "for i in range(num_test*6):\n",
    "    if true_label != i//num_test:\n",
    "        print()\n",
    "        print(f\"Now testing for category {final_categories[i//num_test]}\")\n",
    "    true_label = i//num_test\n",
    "    current_max_score = np.iinfo(np.int32).min\n",
    "    current_label = 0\n",
    "    for j in range(len(hmm_classifier_lists)):\n",
    "        # return log likelihood of each classifier\n",
    "        score = hmm_classifier_lists[j].score(test_set[i])\n",
    "        if score > current_max_score:\n",
    "            current_max_score = score\n",
    "            current_label = j\n",
    "    if true_label == current_label:\n",
    "        print(f\"correct {final_categories[true_label]}\")\n",
    "        num_correct = num_correct + 1\n",
    "    else:\n",
    "        print(f\"wrong {final_categories[true_label]} classified as {final_categories[current_label]} \")\n",
    "print(f\"The prediction accuracy on test set is {num_correct/total_test_data:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "a9c40ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These spectrogram settings look pretty good from a domain perspective.\n",
    "# Trying a little bit higher \"resolution\" than previously\n",
    "mel_settings = {'fmax': 8000, 'power': 2, 'n_mels' :128, 'n_fft':2048, 'hop_length':512}\n",
    "fs_nom = 16000 # Nominal sampling rate. Most files should be this rate, but if not, they will be resampled\n",
    "shape_nom = (128,126) # nominal spectrogram shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "44c4ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn\n",
    "\n",
    "def force_array_shape(x, force_shape):\n",
    "    \"\"\"Forces a numpy array to a specific shape by filling with zeros, or truncating\"\"\"\n",
    "    pad_widths = []\n",
    "    for ax, ax_length in enumerate(force_shape):\n",
    "        if x.shape[ax] >= ax_length:\n",
    "            x = x.take(indices=range(0,ax_length), axis=ax)\n",
    "        pad_widths.append((0,ax_length-x.shape[ax]))\n",
    "    x = np.pad(x, pad_widths)\n",
    "    return x\n",
    "\n",
    "def get_mels(filepath='', data=[], fs=None, force_shape=None):\n",
    "    if filepath:\n",
    "        data, fs = librosa.load(filepath, sr=fs)\n",
    "        if fs != fs_nom:\n",
    "            print(filepath)\n",
    "    else:\n",
    "        assert (len(data>0) and fs >0), 'Must provide either a filename, or array of data and sample rate'\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=data, sr = fs, **mel_settings)\n",
    "    \n",
    "    if force_shape and S.shape != force_shape:\n",
    "        \n",
    "        S = force_array_shape(S, force_shape)\n",
    "            \n",
    "    return S, fs\n",
    " \n",
    "def load_mels(filepath, force_create=False, save=True):\n",
    "    mel_path = filepath.with_suffix('.npy')\n",
    "    \n",
    "    if mel_path.is_file() and not force_create:\n",
    "        #print('Loading {}'.format(mel_path))\n",
    "        mels = np.load(mel_path)\n",
    "    else:\n",
    "        #print('Generating from {}'.format(filepath))\n",
    "        mels, _ = get_mels(filepath, fs=fs_nom, force_shape = shape_nom)\n",
    "        if save:\n",
    "            #print('Saving {}'.format(mel_path))\n",
    "            np.save(mel_path, mels)\n",
    "    \n",
    "    return mels\n",
    "\n",
    "def feature_preprocessing(mel):\n",
    "    # convert to db and normalise\n",
    "    power = librosa.core.power_to_db(mel, ref=np.max)\n",
    "    power = power - np.mean(power)\n",
    "    power = power / (np.std(power))\n",
    "    return power[:, :, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e1ff557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the features\n",
    "# note this will store all features in memory, as well as saving them to disk. \n",
    "# Can't guarantee it will work for large datasets.\n",
    "manifest['features'] = manifest.apply(lambda x: data_root/x['package_hash']/x['filename'], \n",
    "                                      axis=1).apply(lambda x: feature_preprocessing(load_mels(x, force_create=True, save=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "4331b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Support\n",
      "animal_birds                  [[1 0 0 0 0 0]] : 50\n",
      "animal_dogs                   [[0 1 0 0 0 0]] : 50\n",
      "human_voice                   [[0 0 1 0 0 0]] : 50\n",
      "mechanical                    [[0 0 0 1 0 0]] : 50\n",
      "music                         [[0 0 0 0 1 0]] : 50\n",
      "transport_car                 [[0 0 0 0 0 1]] : 50\n",
      "(270, 128, 126, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.stack(manifest['features'].values)\n",
    "y = category_encoder.transform(manifest['category_set'].values)\n",
    "\n",
    "print('Category Support')\n",
    "for c,n in zip(category_encoder.classes_, y.sum(axis=0)):\n",
    "    print('{:30s}{} : {}'.format(c, category_encoder.transform([[c]]), n) )\n",
    "\n",
    "idx_list= list(range(y.shape[0]))\n",
    "for i in range(y.shape[0]):\n",
    "    if np.all((y[i] == 0)):\n",
    "        idx_list.remove(i) \n",
    "X = X[idx_list]\n",
    "y = y[idx_list]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1,random_state=42)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ec60a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "66d26ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_ldnn(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "723b5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    predictions = tf.cast(tf.greater_equal(y_pred, 0.5), tf.float32)\n",
    "    pred_match = tf.equal(predictions, tf.round(y_true))\n",
    "    exact_count = tf.math.reduce_min(tf.cast(pred_match, tf.float32), axis=1)\n",
    "    return exact_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "075368ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 8s 231ms/step - loss: 1.0036 - accuracy: 0.8296 - val_loss: 1.6479 - val_accuracy: 0.4667\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.9959 - accuracy: 0.8481 - val_loss: 1.6721 - val_accuracy: 0.4000\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 1.0017 - accuracy: 0.8593 - val_loss: 1.6410 - val_accuracy: 0.4000\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.9912 - accuracy: 0.8222 - val_loss: 1.6849 - val_accuracy: 0.4333\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.9669 - accuracy: 0.8667 - val_loss: 1.6189 - val_accuracy: 0.4667\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 0.9595 - accuracy: 0.8481 - val_loss: 1.6262 - val_accuracy: 0.4667\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.9329 - accuracy: 0.8889 - val_loss: 1.6282 - val_accuracy: 0.5000\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.9592 - accuracy: 0.8630 - val_loss: 1.6342 - val_accuracy: 0.4333\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.9513 - accuracy: 0.8667 - val_loss: 1.6406 - val_accuracy: 0.4667\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.9508 - accuracy: 0.9111 - val_loss: 1.7044 - val_accuracy: 0.4000\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.9139 - accuracy: 0.8815 - val_loss: 1.6918 - val_accuracy: 0.4333\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 0.9344 - accuracy: 0.8741 - val_loss: 1.7005 - val_accuracy: 0.3667\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.9250 - accuracy: 0.8815 - val_loss: 1.6840 - val_accuracy: 0.4000\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.8750 - accuracy: 0.9037 - val_loss: 1.6469 - val_accuracy: 0.4333\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 0.9040 - accuracy: 0.8630 - val_loss: 1.6301 - val_accuracy: 0.4000\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 0.9212 - accuracy: 0.8741 - val_loss: 1.6433 - val_accuracy: 0.4333\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 0.8657 - accuracy: 0.9074 - val_loss: 1.6832 - val_accuracy: 0.4000\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 0.8547 - accuracy: 0.9037 - val_loss: 1.6903 - val_accuracy: 0.3333\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 0.8390 - accuracy: 0.9111 - val_loss: 1.6872 - val_accuracy: 0.4333\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 0.8706 - accuracy: 0.8926 - val_loss: 1.7268 - val_accuracy: 0.4667\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1e-5), metrics=['accuracy'])\n",
    "\n",
    "# use the following for validation and training\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f8b14",
   "metadata": {},
   "source": [
    "## Testing Stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1a1678af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 0, 0, 4, 2, 3, 2, 5, 3, 3, 1, 2, 0, 3, 4, 5, 2, 2, 5, 1, 3,\n",
       "       2, 4, 0, 3, 2, 5, 3, 2], dtype=int64)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(X_test)\n",
    "y_pred=y_pred.argmax(axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "b11a65f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 3, 0, 4, 4, 3, 2, 0, 3, 4, 1, 4, 0, 3, 4, 5, 4, 2, 3, 1, 2,\n",
       "       4, 5, 2, 0, 5, 5, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_true = np.where(y_test==1)[1]\n",
    "y_test_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "6ea8f462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy for the CNN is 0.47\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == y_test_true[i]:\n",
    "        count = count + 1\n",
    "print(f\"The prediction accuracy for the CNN is {count/len(y_pred):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "ba2ca457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  animal_dogs       0.50      0.50      0.50         4\n",
      " animal_birds       1.00      1.00      1.00         2\n",
      "  human_voice       0.25      0.50      0.33         4\n",
      "transport_car       0.44      0.67      0.53         6\n",
      "        music       0.67      0.22      0.33         9\n",
      "   mechanical       0.50      0.40      0.44         5\n",
      "\n",
      "     accuracy                           0.47        30\n",
      "    macro avg       0.56      0.55      0.52        30\n",
      " weighted avg       0.54      0.47      0.46        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_true, y_pred, target_names=final_categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
