{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2a9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ef2b6",
   "metadata": {},
   "source": [
    "# DNN model 1 (Densenet)\n",
    "\n",
    "Below is our own implementation of densenet, following the tutorial in\n",
    "https://amaarora.github.io/2020/08/02/densenets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c7afe82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dense_net(initial_feature, num_label, input_shape, \n",
    "              dense_block_config, drop_out = 0.2, bottle_necksz=4, growth_rate=32):\n",
    "    \n",
    "    def dense_block(input_layer, num_sets, bottle_necksz, growth_rate):\n",
    "        layer_sets = [input_layer]\n",
    "        for i in range(num_sets):\n",
    "            if i > 0:\n",
    "                input_layer = keras.layers.Concatenate()(layer_sets)\n",
    "                layer_sets = []\n",
    "                layer_sets.append(input_layer)\n",
    "            bottleneck_1 = keras.layers.BatchNormalization()(input_layer)\n",
    "            activation_1 = keras.layers.ReLU()(bottleneck_1)\n",
    "            convolution_1 = keras.layers.Conv2D(bottle_necksz*growth_rate,\n",
    "                                                kernel_size=(1,1), strides=1, use_bias=False)(activation_1)\n",
    "            bottleneck_2 = keras.layers.BatchNormalization()(convolution_1)\n",
    "            activation_2 =  keras.layers.ReLU()(bottleneck_2)\n",
    "            convolution_2 = keras.layers.Conv2D(growth_rate, kernel_size=(3,3), \n",
    "                                                strides=1, padding='same', use_bias=False)(activation_2)\n",
    "            layer_sets.append(convolution_2)\n",
    "        return keras.layers.Concatenate()(layer_sets)\n",
    "\n",
    "    def transition_layer(input_layer):\n",
    "        batch_norm = keras.layers.BatchNormalization()(input_layer)\n",
    "        activation = keras.layers.ReLU()(batch_norm)\n",
    "        feature_size = keras.backend.int_shape(activation)[3]\n",
    "        conv = keras.layers.Conv2D(feature_size//2, kernel_size=(1,1),strides=1,use_bias=False)(activation)\n",
    "        pool = keras.layers.AveragePooling2D()(conv)\n",
    "        return pool\n",
    "\n",
    "    def fully_connected_layer(input_layer, num_labels):\n",
    "        pool = keras.layers.GlobalAveragePooling2D()(input_layer)\n",
    "        norm_1 = keras.layers.BatchNormalization()(pool)\n",
    "        dropout = keras.layers.Dropout(.2)(norm_1)\n",
    "        dense_1 = keras.layers.Dense(1024, activation='relu')(dropout)\n",
    "        dense_2 = keras.layers.Dense(512, activation='relu')(dense_1)\n",
    "        norm_2 = keras.layers.BatchNormalization()(dense_2)\n",
    "        dropout_2 = keras.layers.Dropout(.2)(norm_2)\n",
    "        return keras.layers.Dense(num_labels, activation='softmax')(dropout_2)\n",
    "\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    # initial transition layers\n",
    "    initial_padding_1 = keras.layers.ZeroPadding2D(padding=(3,3))(inputs)\n",
    "    initial_conv = keras.layers.Conv2D(initial_feature, kernel_size=(7,7), \n",
    "                                       strides=2, use_bias=False)(initial_padding_1)\n",
    "    initial_norm = keras.layers.BatchNormalization()(initial_conv)\n",
    "    initial_relu = keras.layers.ReLU()(initial_norm)\n",
    "    initial_padding_2 = keras.layers.ZeroPadding2D(padding=(1,1))(initial_relu)\n",
    "    initial = keras.layers.MaxPooling2D(pool_size=(3,3), strides=2)(initial_padding_2)\n",
    "    \n",
    "    for num in dense_block_config:\n",
    "        conv = dense_block(initial, num, bottle_necksz, growth_rate)\n",
    "        initial = transition_layer(conv)\n",
    "\n",
    "    outputs = fully_connected_layer(initial, num_label)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03012c7",
   "metadata": {},
   "source": [
    "## DNN model 2 (Convolutional LSTM)\n",
    "Below is the Convolutional LSTM used in https://github.com/WWH98932/Audio-Classification-Models\n",
    "\n",
    "ResNet50 is discussed in the project report. The original paper for resnet is at https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9f9143e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras import regularizers\n",
    "\n",
    "def resnet_ldnn(num_label):\n",
    "    model = Sequential()\n",
    "    model.add(keras.applications.resnet50.ResNet50(include_top=False, input_shape=(128, 126, 1), \n",
    "                                                   weights=None, classes=None, pooling='average'))\n",
    "    model.add(Permute((2, 1, 3)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(64, dropout=0.25, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.25))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_label, kernel_regularizer=regularizers.l2(0.01), activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadadf29",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d1278e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import ast\n",
    "\n",
    "# Read data from path\n",
    "data_root = pathlib.Path('sample_set\\\\')\n",
    "manifest = pd.read_csv(\"sample_set\\\\01_manifest.csv\")\n",
    "manifest['tag_set'] = manifest['tag_set'].apply(ast.literal_eval)\n",
    "manifest['category_set'] = manifest['category_set'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7fc503a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['animal_birds', 'animal_dogs', 'background', 'human_voice',\n",
       "       'mechanical', 'transport_car'], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "final_categories = ['animal_dogs', 'animal_birds', 'human_voice', 'transport_car','background','mechanical']\n",
    "category_encoder = MultiLabelBinarizer().fit([final_categories])\n",
    "category_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9c40ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These spectrogram settings look pretty good from a domain perspective.\n",
    "# Trying a little bit higher \"resolution\" than previously\n",
    "mel_settings = {'fmax': 8000, 'power': 2, 'n_mels' :128, 'n_fft':2048, 'hop_length':512}\n",
    "fs_nom = 16000 # Nominal sampling rate. Most files should be this rate, but if not, they will be resampled\n",
    "shape_nom = (128,126) # nominal spectrogram shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44c4ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn\n",
    "\n",
    "def force_array_shape(x, force_shape):\n",
    "    \"\"\"Forces a numpy array to a specific shape by filling with zeros, or truncating\"\"\"\n",
    "    pad_widths = []\n",
    "    for ax, ax_length in enumerate(force_shape):\n",
    "        if x.shape[ax] >= ax_length:\n",
    "            x = x.take(indices=range(0,ax_length), axis=ax)\n",
    "        pad_widths.append((0,ax_length-x.shape[ax]))\n",
    "    x = np.pad(x, pad_widths)\n",
    "    return x\n",
    "\n",
    "def get_mels(filepath='', data=[], fs=None, force_shape=None):\n",
    "    if filepath:\n",
    "        data, fs = librosa.load(filepath, sr=fs)\n",
    "        if fs != fs_nom:\n",
    "            print(filepath)\n",
    "    else:\n",
    "        assert (len(data>0) and fs >0), 'Must provide either a filename, or array of data and sample rate'\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=data, sr = fs, **mel_settings)\n",
    "    \n",
    "    if force_shape and S.shape != force_shape:\n",
    "        \n",
    "        S = force_array_shape(S, force_shape)\n",
    "            \n",
    "    return S, fs\n",
    " \n",
    "def load_mels(filepath, force_create=False, save=True):\n",
    "    mel_path = filepath.with_suffix('.npy')\n",
    "    \n",
    "    if mel_path.is_file() and not force_create:\n",
    "        #print('Loading {}'.format(mel_path))\n",
    "        mels = np.load(mel_path)\n",
    "    else:\n",
    "        #print('Generating from {}'.format(filepath))\n",
    "        mels, _ = get_mels(filepath, fs=fs_nom, force_shape = shape_nom)\n",
    "        if save:\n",
    "            #print('Saving {}'.format(mel_path))\n",
    "            np.save(mel_path, mels)\n",
    "    \n",
    "    return mels\n",
    "\n",
    "def feature_preprocessing(mel):\n",
    "    # convert to db and normalise\n",
    "    power = librosa.core.power_to_db(mel, ref=np.max)\n",
    "    power = power - np.mean(power)\n",
    "    power = power / (np.std(power))\n",
    "    return power[:, :, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e1ff557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the features\n",
    "# note this will store all features in memory, as well as saving them to disk. \n",
    "# Can't guarantee it will work for large datasets.\n",
    "manifest['features'] = manifest.apply(lambda x: data_root/x['package_hash']/x['filename'], axis=1).apply(lambda x: feature_preprocessing(load_mels(x, force_create=True, save=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4331b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Support\n",
      "animal_birds                  [[1 0 0 0 0 0]] : 2382\n",
      "animal_dogs                   [[0 1 0 0 0 0]] : 2229\n",
      "background                    [[0 0 1 0 0 0]] : 915\n",
      "human_voice                   [[0 0 0 1 0 0]] : 964\n",
      "mechanical                    [[0 0 0 0 1 0]] : 2099\n",
      "transport_car                 [[0 0 0 0 0 1]] : 1251\n",
      "(4379, 128, 126, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.stack(manifest['features'].values)\n",
    "y = category_encoder.transform(manifest['category_set'].values)\n",
    "\n",
    "print('Category Support')\n",
    "for c,n in zip(category_encoder.classes_, y.sum(axis=0)):\n",
    "    print('{:30s}{} : {}'.format(c, category_encoder.transform([[c]]), n) )\n",
    "\n",
    "idx_list= list(range(y.shape[0]))\n",
    "for i in range(y.shape[0]):\n",
    "    if np.all((y[i] == 0)):\n",
    "        idx_list.remove(i) \n",
    "X = X[idx_list]\n",
    "y = y[idx_list]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ec60a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e28452c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel of the first convolutional layer\n",
    "initial_feature = 64  \n",
    "# number of labels to be categorized\n",
    "num_labels = 6\n",
    "input_shape = (128, 126, 1)\n",
    "dense_block_config=(6, 12, 24, 16)\n",
    "model = dense_net(initial_feature, num_labels, input_shape, dense_block_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "66d26ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_ldnn(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "075368ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - 17s 80ms/step - loss: 0.1738\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1e-5))\n",
    "\n",
    "# use the following for validation and training\n",
    "# history = model.fit(X_train, y_train, epochs=500, validation_data=(X_val, y_val))\n",
    "\n",
    "# The following line is used for manual stopping of the network training\n",
    "history = model.fit(X_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f8b14",
   "metadata": {},
   "source": [
    "## Testing Stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1a1678af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6ea8f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities to class labels (one-hot encoding)\n",
    "y_pred[y_pred>=0.5] = 1\n",
    "y_pred[y_pred<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6c8c60b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8747433264887063"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exact match rate \n",
    "# code used from https://medium.com/analytics-vidhya/metrics-for-multi-label-classification-49cc5aeba1c3\n",
    "# This function determines the rate of exact \n",
    "def emr(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    row_indicators = np.all(y_true == y_pred, axis = 1) \n",
    "    exact_match_count = np.sum(row_indicators)\n",
    "    return exact_match_count/n\n",
    "\n",
    "emr(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ba2ca457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "  animal_dogs       0.93      0.95      0.94       250\n",
      " animal_birds       0.97      0.96      0.96       226\n",
      "  human_voice       0.96      0.91      0.93       100\n",
      "transport_car       0.99      0.84      0.91        99\n",
      "   background       0.93      0.96      0.95       210\n",
      "   mechanical       0.95      0.85      0.90       124\n",
      "\n",
      "    micro avg       0.95      0.93      0.94      1009\n",
      "    macro avg       0.95      0.91      0.93      1009\n",
      " weighted avg       0.95      0.93      0.94      1009\n",
      "  samples avg       0.94      0.93      0.93      1009\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=final_categories))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
