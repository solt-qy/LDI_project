{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2a9daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276ef2b6",
   "metadata": {},
   "source": [
    "# DNN model 1 (Densenet)\n",
    "\n",
    "Below is our own implementation of densenet, following the tutorial in\n",
    "https://amaarora.github.io/2020/08/02/densenets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c7afe82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def dense_net(initial_feature, num_label, input_shape, \n",
    "              dense_block_config, drop_out = 0.2, bottle_necksz=4, growth_rate=32):\n",
    "    \n",
    "    def dense_block(input_layer, num_sets, bottle_necksz, growth_rate):\n",
    "        layer_sets = [input_layer]\n",
    "        for i in range(num_sets):\n",
    "            if i > 0:\n",
    "                input_layer = keras.layers.Concatenate()(layer_sets)\n",
    "                layer_sets = []\n",
    "                layer_sets.append(input_layer)\n",
    "            bottleneck_1 = keras.layers.BatchNormalization()(input_layer)\n",
    "            activation_1 = keras.layers.ReLU()(bottleneck_1)\n",
    "            convolution_1 = keras.layers.Conv2D(bottle_necksz*growth_rate,\n",
    "                                                kernel_size=(1,1), strides=1, use_bias=False)(activation_1)\n",
    "            bottleneck_2 = keras.layers.BatchNormalization()(convolution_1)\n",
    "            activation_2 =  keras.layers.ReLU()(bottleneck_2)\n",
    "            convolution_2 = keras.layers.Conv2D(growth_rate, kernel_size=(3,3), \n",
    "                                                strides=1, padding='same', use_bias=False)(activation_2)\n",
    "            layer_sets.append(convolution_2)\n",
    "        return keras.layers.Concatenate()(layer_sets)\n",
    "\n",
    "    def transition_layer(input_layer):\n",
    "        batch_norm = keras.layers.BatchNormalization()(input_layer)\n",
    "        activation = keras.layers.ReLU()(batch_norm)\n",
    "        feature_size = keras.backend.int_shape(activation)[3]\n",
    "        conv = keras.layers.Conv2D(feature_size//2, kernel_size=(1,1),strides=1,use_bias=False)(activation)\n",
    "        pool = keras.layers.AveragePooling2D()(conv)\n",
    "        return pool\n",
    "\n",
    "    def fully_connected_layer(input_layer, num_labels):\n",
    "        pool = keras.layers.GlobalAveragePooling2D()(input_layer)\n",
    "        norm_1 = keras.layers.BatchNormalization()(pool)\n",
    "        dropout = keras.layers.Dropout(.2)(norm_1)\n",
    "        dense_1 = keras.layers.Dense(1024, activation='relu')(dropout)\n",
    "        dense_2 = keras.layers.Dense(512, activation='relu')(dense_1)\n",
    "        norm_2 = keras.layers.BatchNormalization()(dense_2)\n",
    "        dropout_2 = keras.layers.Dropout(.2)(norm_2)\n",
    "        return keras.layers.Dense(num_labels, activation='softmax')(dropout_2)\n",
    "\n",
    "    inputs = keras.Input(shape = input_shape)\n",
    "    # initial transition layers\n",
    "    initial_padding_1 = keras.layers.ZeroPadding2D(padding=(3,3))(inputs)\n",
    "    initial_conv = keras.layers.Conv2D(initial_feature, kernel_size=(7,7), \n",
    "                                       strides=2, use_bias=False)(initial_padding_1)\n",
    "    initial_norm = keras.layers.BatchNormalization()(initial_conv)\n",
    "    initial_relu = keras.layers.ReLU()(initial_norm)\n",
    "    initial_padding_2 = keras.layers.ZeroPadding2D(padding=(1,1))(initial_relu)\n",
    "    initial = keras.layers.MaxPooling2D(pool_size=(3,3), strides=2)(initial_padding_2)\n",
    "    \n",
    "    for num in dense_block_config:\n",
    "        conv = dense_block(initial, num, bottle_necksz, growth_rate)\n",
    "        initial = transition_layer(conv)\n",
    "\n",
    "    outputs = fully_connected_layer(initial, num_label)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03012c7",
   "metadata": {},
   "source": [
    "## DNN model 2 (Convolutional LSTM)\n",
    "Below is the Convolutional LSTM used in https://github.com/WWH98932/Audio-Classification-Models\n",
    "\n",
    "ResNet50 is discussed in the project report. The original paper for resnet is at https://arxiv.org/pdf/1512.03385.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9f9143e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras import regularizers\n",
    "\n",
    "def resnet_ldnn(num_label):\n",
    "    model = Sequential()\n",
    "    model.add(keras.applications.resnet50.ResNet50(include_top=False, input_shape=(128, 126, 1), \n",
    "                                                   weights=None, classes=None, pooling='average'))\n",
    "    model.add(Permute((2, 1, 3)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(64, dropout=0.3, return_sequences=True))\n",
    "    model.add(LSTM(64, dropout=0.3))\n",
    "    model.add(Dense(64))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_label, kernel_regularizer=regularizers.l2(0.03), activation='sigmoid'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadadf29",
   "metadata": {},
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d1278e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>package_hash</th>\n",
       "      <th>manual_tag</th>\n",
       "      <th>tag_set</th>\n",
       "      <th>category_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101729-0-0-1.wav</td>\n",
       "      <td>u8k_fold9</td>\n",
       "      <td>air_conditioner</td>\n",
       "      <td>{air_conditioner}</td>\n",
       "      <td>{mechanical}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>103249-5-0-1.wav</td>\n",
       "      <td>u8k_fold9</td>\n",
       "      <td>engine_idling</td>\n",
       "      <td>{engine_idling}</td>\n",
       "      <td>{transport_car}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104817-4-0-11.wav</td>\n",
       "      <td>u8k_fold2</td>\n",
       "      <td>drilling</td>\n",
       "      <td>{drilling}</td>\n",
       "      <td>{mechanical_construction}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104998-7-16-0.wav</td>\n",
       "      <td>u8k_fold5</td>\n",
       "      <td>jackhammer</td>\n",
       "      <td>{jackhammer}</td>\n",
       "      <td>{mechanical_construction}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104998-7-18-3.wav</td>\n",
       "      <td>u8k_fold5</td>\n",
       "      <td>jackhammer</td>\n",
       "      <td>{jackhammer}</td>\n",
       "      <td>{mechanical_construction}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4959</th>\n",
       "      <td>75490-8-1-0.wav</td>\n",
       "      <td>u8k_fold6</td>\n",
       "      <td>siren</td>\n",
       "      <td>{siren}</td>\n",
       "      <td>{signals_siren}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4960</th>\n",
       "      <td>76085-4-0-61.wav</td>\n",
       "      <td>u8k_fold8</td>\n",
       "      <td>drilling</td>\n",
       "      <td>{drilling}</td>\n",
       "      <td>{mechanical_construction}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>81787-2-0-23.wav</td>\n",
       "      <td>u8k_fold8</td>\n",
       "      <td>children_playing</td>\n",
       "      <td>{children_playing}</td>\n",
       "      <td>{human_voice}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4962</th>\n",
       "      <td>87275-1-3-0.wav</td>\n",
       "      <td>u8k_fold1</td>\n",
       "      <td>car_horn</td>\n",
       "      <td>{car_horn}</td>\n",
       "      <td>{signals_horn}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>91209-5-0-1.wav</td>\n",
       "      <td>u8k_fold8</td>\n",
       "      <td>engine_idling</td>\n",
       "      <td>{engine_idling}</td>\n",
       "      <td>{transport_car}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4964 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename package_hash        manual_tag             tag_set  \\\n",
       "0      101729-0-0-1.wav    u8k_fold9   air_conditioner   {air_conditioner}   \n",
       "1      103249-5-0-1.wav    u8k_fold9     engine_idling     {engine_idling}   \n",
       "2     104817-4-0-11.wav    u8k_fold2          drilling          {drilling}   \n",
       "3     104998-7-16-0.wav    u8k_fold5        jackhammer        {jackhammer}   \n",
       "4     104998-7-18-3.wav    u8k_fold5        jackhammer        {jackhammer}   \n",
       "...                 ...          ...               ...                 ...   \n",
       "4959    75490-8-1-0.wav    u8k_fold6             siren             {siren}   \n",
       "4960   76085-4-0-61.wav    u8k_fold8          drilling          {drilling}   \n",
       "4961   81787-2-0-23.wav    u8k_fold8  children_playing  {children_playing}   \n",
       "4962    87275-1-3-0.wav    u8k_fold1          car_horn          {car_horn}   \n",
       "4963    91209-5-0-1.wav    u8k_fold8     engine_idling     {engine_idling}   \n",
       "\n",
       "                   category_set  \n",
       "0                  {mechanical}  \n",
       "1               {transport_car}  \n",
       "2     {mechanical_construction}  \n",
       "3     {mechanical_construction}  \n",
       "4     {mechanical_construction}  \n",
       "...                         ...  \n",
       "4959            {signals_siren}  \n",
       "4960  {mechanical_construction}  \n",
       "4961              {human_voice}  \n",
       "4962             {signals_horn}  \n",
       "4963            {transport_car}  \n",
       "\n",
       "[4964 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import ast\n",
    "\n",
    "# Read data from path\n",
    "data_root = pathlib.Path('sample_set\\\\')\n",
    "manifest = pd.read_csv(\"sample_set\\\\01_manifest.csv\")\n",
    "manifest['tag_set'] = manifest['tag_set'].apply(ast.literal_eval)\n",
    "manifest['category_set'] = manifest['category_set'].apply(ast.literal_eval)\n",
    "manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fc503a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['animal_birds', 'animal_dogs', 'animal_insects', 'mechanical',\n",
       "       'transport_car'], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "final_categories = ['animal_dogs', 'animal_birds','animal_insects', 'mechanical', 'transport_car']\n",
    "category_encoder = MultiLabelBinarizer().fit([final_categories])\n",
    "category_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a9c40ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These spectrogram settings look pretty good from a domain perspective.\n",
    "# Trying a little bit higher \"resolution\" than previously\n",
    "mel_settings = {'fmax': 8000, 'power': 2, 'n_mels' :128, 'n_fft':2048, 'hop_length':512}\n",
    "fs_nom = 16000 # Nominal sampling rate. Most files should be this rate, but if not, they will be resampled\n",
    "shape_nom = (128,126) # nominal spectrogram shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44c4ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import librosa.display\n",
    "import sklearn\n",
    "\n",
    "def force_array_shape(x, force_shape):\n",
    "    \"\"\"Forces a numpy array to a specific shape by filling with zeros, or truncating\"\"\"\n",
    "    pad_widths = []\n",
    "    for ax, ax_length in enumerate(force_shape):\n",
    "        if x.shape[ax] >= ax_length:\n",
    "            x = x.take(indices=range(0,ax_length), axis=ax)\n",
    "        pad_widths.append((0,ax_length-x.shape[ax]))\n",
    "    x = np.pad(x, pad_widths)\n",
    "    return x\n",
    "\n",
    "def get_mels(filepath='', data=[], fs=None, force_shape=None):\n",
    "    if filepath:\n",
    "        data, fs = librosa.load(filepath, sr=fs)\n",
    "        if fs != fs_nom:\n",
    "            print(filepath)\n",
    "    else:\n",
    "        assert (len(data>0) and fs >0), 'Must provide either a filename, or array of data and sample rate'\n",
    "    \n",
    "    S = librosa.feature.melspectrogram(y=data, sr = fs, **mel_settings)\n",
    "    \n",
    "    if force_shape and S.shape != force_shape:\n",
    "        \n",
    "        S = force_array_shape(S, force_shape)\n",
    "            \n",
    "    return S, fs\n",
    " \n",
    "def load_mels(filepath, force_create=False, save=True):\n",
    "    mel_path = filepath.with_suffix('.npy')\n",
    "    \n",
    "    if mel_path.is_file() and not force_create:\n",
    "        #print('Loading {}'.format(mel_path))\n",
    "        mels = np.load(mel_path)\n",
    "    else:\n",
    "        #print('Generating from {}'.format(filepath))\n",
    "        mels, _ = get_mels(filepath, fs=fs_nom, force_shape = shape_nom)\n",
    "        if save:\n",
    "            #print('Saving {}'.format(mel_path))\n",
    "            np.save(mel_path, mels)\n",
    "    \n",
    "    return mels\n",
    "\n",
    "def feature_preprocessing(mel):\n",
    "    # convert to db and normalise\n",
    "    power = librosa.core.power_to_db(mel, ref=np.max)\n",
    "    power = power - np.mean(power)\n",
    "    power = power / (np.std(power))\n",
    "    return power[:, :, None]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1ff557b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the features\n",
    "# note this will store all features in memory, as well as saving them to disk. \n",
    "# Can't guarantee it will work for large datasets.\n",
    "manifest['features'] = manifest.apply(lambda x: data_root/x['package_hash']/x['filename'], axis=1).apply(lambda x: feature_preprocessing(load_mels(x, force_create=True, save=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4331b938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:875: UserWarning: unknown class(es) ['animal_cockatoo', 'animal_other', 'animal_poultry', 'background', 'human_movement', 'human_voice', 'indeterminate', 'mechanical_construction', 'mechanical_impulsive', 'music', 'nature_wind', 'signals_bell', 'signals_horn', 'signals_siren', 'transport_aircraft', 'transport_motorcycle'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category Support\n",
      "animal_birds                  [[1 0 0 0 0]] : 2382\n",
      "animal_dogs                   [[0 1 0 0 0]] : 2229\n",
      "animal_insects                [[0 0 1 0 0]] : 677\n",
      "mechanical                    [[0 0 0 1 0]] : 2099\n",
      "transport_car                 [[0 0 0 0 1]] : 1251\n",
      "(4652, 128, 126, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.stack(manifest['features'].values)\n",
    "y = category_encoder.transform(manifest['category_set'].values)\n",
    "\n",
    "print('Category Support')\n",
    "for c,n in zip(category_encoder.classes_, y.sum(axis=0)):\n",
    "    print('{:30s}{} : {}'.format(c, category_encoder.transform([[c]]), n) )\n",
    "\n",
    "idx_list= list(range(y.shape[0]))\n",
    "for i in range(y.shape[0]):\n",
    "    if np.all((y[i] == 0)):\n",
    "        idx_list.remove(i) \n",
    "X = X[idx_list]\n",
    "y = y[idx_list]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5ec60a",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e28452c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dense_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28520/3506605249.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m126\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdense_block_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m48\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdense_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_block_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dense_net' is not defined"
     ]
    }
   ],
   "source": [
    "# channel of the first convolutional layer\n",
    "initial_feature = 64  \n",
    "# number of labels to be categorized\n",
    "num_labels = 6\n",
    "input_shape = (128, 126, 1)\n",
    "dense_block_config=(6, 12, 48, 32)\n",
    "model = dense_net(initial_feature, num_labels, input_shape, dense_block_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "66d26ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet_ldnn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "723b5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred):\n",
    "    predictions = tf.cast(tf.greater_equal(y_pred, 0.5), tf.float32)\n",
    "    pred_match = tf.equal(predictions, tf.round(y_true))\n",
    "    exact_count = tf.math.reduce_min(tf.cast(pred_match, tf.float32), axis=1)\n",
    "    return exact_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "075368ce",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "118/118 [==============================] - 18s 101ms/step - loss: 0.9119 - custom_metric: 0.0520 - val_loss: 0.8930 - val_custom_metric: 0.0000e+00\n",
      "Epoch 2/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.8834 - custom_metric: 0.0611 - val_loss: 0.8783 - val_custom_metric: 0.0000e+00\n",
      "Epoch 3/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.8746 - custom_metric: 0.0677 - val_loss: 0.8720 - val_custom_metric: 0.0000e+00\n",
      "Epoch 4/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.8701 - custom_metric: 0.0661 - val_loss: 0.8634 - val_custom_metric: 0.0239\n",
      "Epoch 5/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.8649 - custom_metric: 0.0751 - val_loss: 0.8545 - val_custom_metric: 0.0310\n",
      "Epoch 6/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.8618 - custom_metric: 0.0770 - val_loss: 0.8479 - val_custom_metric: 0.0549\n",
      "Epoch 7/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.8567 - custom_metric: 0.0772 - val_loss: 0.8441 - val_custom_metric: 0.0573\n",
      "Epoch 8/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.8515 - custom_metric: 0.0791 - val_loss: 0.8404 - val_custom_metric: 0.0788\n",
      "Epoch 9/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.8481 - custom_metric: 0.0746 - val_loss: 0.8357 - val_custom_metric: 0.0764\n",
      "Epoch 10/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.8448 - custom_metric: 0.0842 - val_loss: 0.8308 - val_custom_metric: 0.0811\n",
      "Epoch 11/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.8378 - custom_metric: 0.0868 - val_loss: 0.8264 - val_custom_metric: 0.0955\n",
      "Epoch 12/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.8361 - custom_metric: 0.0900 - val_loss: 0.8233 - val_custom_metric: 0.0931\n",
      "Epoch 13/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.8326 - custom_metric: 0.0929 - val_loss: 0.8194 - val_custom_metric: 0.1050\n",
      "Epoch 14/500\n",
      "118/118 [==============================] - 11s 89ms/step - loss: 0.8279 - custom_metric: 0.0953 - val_loss: 0.8142 - val_custom_metric: 0.1026\n",
      "Epoch 15/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.8229 - custom_metric: 0.1035 - val_loss: 0.8110 - val_custom_metric: 0.1337\n",
      "Epoch 16/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.8183 - custom_metric: 0.0924 - val_loss: 0.8087 - val_custom_metric: 0.1146\n",
      "Epoch 17/500\n",
      "118/118 [==============================] - 11s 90ms/step - loss: 0.8120 - custom_metric: 0.1080 - val_loss: 0.8035 - val_custom_metric: 0.1193\n",
      "Epoch 18/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.8078 - custom_metric: 0.1088 - val_loss: 0.7997 - val_custom_metric: 0.1169\n",
      "Epoch 19/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.8034 - custom_metric: 0.1139 - val_loss: 0.7974 - val_custom_metric: 0.1122\n",
      "Epoch 20/500\n",
      "118/118 [==============================] - 11s 90ms/step - loss: 0.7986 - custom_metric: 0.1184 - val_loss: 0.7892 - val_custom_metric: 0.1384\n",
      "Epoch 21/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.7934 - custom_metric: 0.1168 - val_loss: 0.7879 - val_custom_metric: 0.1289\n",
      "Epoch 22/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.7890 - custom_metric: 0.1264 - val_loss: 0.7863 - val_custom_metric: 0.1456\n",
      "Epoch 23/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.7824 - custom_metric: 0.1245 - val_loss: 0.7830 - val_custom_metric: 0.1551\n",
      "Epoch 24/500\n",
      "118/118 [==============================] - 11s 90ms/step - loss: 0.7728 - custom_metric: 0.1431 - val_loss: 0.7761 - val_custom_metric: 0.1647\n",
      "Epoch 25/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.7617 - custom_metric: 0.1476 - val_loss: 0.7748 - val_custom_metric: 0.1504\n",
      "Epoch 26/500\n",
      "118/118 [==============================] - 11s 91ms/step - loss: 0.7547 - custom_metric: 0.1590 - val_loss: 0.7702 - val_custom_metric: 0.1504\n",
      "Epoch 27/500\n",
      "118/118 [==============================] - 11s 89ms/step - loss: 0.7493 - custom_metric: 0.1526 - val_loss: 0.7764 - val_custom_metric: 0.1289\n",
      "Epoch 28/500\n",
      "118/118 [==============================] - 11s 90ms/step - loss: 0.7408 - custom_metric: 0.1683 - val_loss: 0.7832 - val_custom_metric: 0.1504\n",
      "Epoch 29/500\n",
      "118/118 [==============================] - 11s 89ms/step - loss: 0.7294 - custom_metric: 0.1781 - val_loss: 0.7616 - val_custom_metric: 0.1766\n",
      "Epoch 30/500\n",
      "118/118 [==============================] - 10s 89ms/step - loss: 0.7230 - custom_metric: 0.1874 - val_loss: 0.7662 - val_custom_metric: 0.1838\n",
      "Epoch 31/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.7103 - custom_metric: 0.2020 - val_loss: 0.7742 - val_custom_metric: 0.1695\n",
      "Epoch 32/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.7018 - custom_metric: 0.2060 - val_loss: 0.7563 - val_custom_metric: 0.1742\n",
      "Epoch 33/500\n",
      "118/118 [==============================] - 10s 89ms/step - loss: 0.6906 - custom_metric: 0.2262 - val_loss: 0.7709 - val_custom_metric: 0.1766\n",
      "Epoch 34/500\n",
      "118/118 [==============================] - 10s 86ms/step - loss: 0.6823 - custom_metric: 0.2352 - val_loss: 0.7611 - val_custom_metric: 0.1647\n",
      "Epoch 35/500\n",
      "118/118 [==============================] - 11s 93ms/step - loss: 0.6720 - custom_metric: 0.2506 - val_loss: 0.7593 - val_custom_metric: 0.1742\n",
      "Epoch 36/500\n",
      "118/118 [==============================] - 11s 92ms/step - loss: 0.6600 - custom_metric: 0.2612 - val_loss: 0.7602 - val_custom_metric: 0.1766\n",
      "Epoch 37/500\n",
      "118/118 [==============================] - 11s 97ms/step - loss: 0.6516 - custom_metric: 0.2641 - val_loss: 0.7700 - val_custom_metric: 0.1766\n",
      "Epoch 38/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.6441 - custom_metric: 0.2822 - val_loss: 0.7530 - val_custom_metric: 0.1933\n",
      "Epoch 39/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.6384 - custom_metric: 0.2745 - val_loss: 0.7698 - val_custom_metric: 0.1838\n",
      "Epoch 40/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.6241 - custom_metric: 0.2891 - val_loss: 0.7618 - val_custom_metric: 0.1695\n",
      "Epoch 41/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.6157 - custom_metric: 0.3109 - val_loss: 0.7602 - val_custom_metric: 0.1742\n",
      "Epoch 42/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.5989 - custom_metric: 0.3332 - val_loss: 0.7613 - val_custom_metric: 0.1742\n",
      "Epoch 43/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.5951 - custom_metric: 0.3467 - val_loss: 0.7560 - val_custom_metric: 0.1742\n",
      "Epoch 44/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.5817 - custom_metric: 0.3557 - val_loss: 0.7600 - val_custom_metric: 0.1862\n",
      "Epoch 45/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.5730 - custom_metric: 0.3517 - val_loss: 0.7609 - val_custom_metric: 0.1551\n",
      "Epoch 46/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.5652 - custom_metric: 0.3727 - val_loss: 0.7733 - val_custom_metric: 0.1742\n",
      "Epoch 47/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.5620 - custom_metric: 0.3682 - val_loss: 0.7668 - val_custom_metric: 0.1957\n",
      "Epoch 48/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.5540 - custom_metric: 0.3730 - val_loss: 0.7741 - val_custom_metric: 0.1766\n",
      "Epoch 49/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.5435 - custom_metric: 0.3905 - val_loss: 0.7842 - val_custom_metric: 0.1551\n",
      "Epoch 50/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.5346 - custom_metric: 0.4035 - val_loss: 0.7766 - val_custom_metric: 0.1766\n",
      "Epoch 51/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.5293 - custom_metric: 0.4019 - val_loss: 0.8116 - val_custom_metric: 0.1623\n",
      "Epoch 52/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.5208 - custom_metric: 0.4176 - val_loss: 0.7975 - val_custom_metric: 0.1814\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118/118 [==============================] - 10s 87ms/step - loss: 0.5169 - custom_metric: 0.4367 - val_loss: 0.8039 - val_custom_metric: 0.1671\n",
      "Epoch 54/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.5036 - custom_metric: 0.4539 - val_loss: 0.7753 - val_custom_metric: 0.1647\n",
      "Epoch 55/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4940 - custom_metric: 0.4595 - val_loss: 0.7842 - val_custom_metric: 0.1456\n",
      "Epoch 56/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4861 - custom_metric: 0.4675 - val_loss: 0.7935 - val_custom_metric: 0.1718\n",
      "Epoch 57/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4822 - custom_metric: 0.4746 - val_loss: 0.8071 - val_custom_metric: 0.1456\n",
      "Epoch 58/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4742 - custom_metric: 0.4847 - val_loss: 0.7959 - val_custom_metric: 0.1551\n",
      "Epoch 59/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4655 - custom_metric: 0.5060 - val_loss: 0.8114 - val_custom_metric: 0.1432\n",
      "Epoch 60/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4610 - custom_metric: 0.5089 - val_loss: 0.8185 - val_custom_metric: 0.1718\n",
      "Epoch 61/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4591 - custom_metric: 0.5105 - val_loss: 0.8015 - val_custom_metric: 0.1718\n",
      "Epoch 62/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4516 - custom_metric: 0.5192 - val_loss: 0.7934 - val_custom_metric: 0.1504\n",
      "Epoch 63/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4417 - custom_metric: 0.5264 - val_loss: 0.7985 - val_custom_metric: 0.1766\n",
      "Epoch 64/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4353 - custom_metric: 0.5418 - val_loss: 0.8252 - val_custom_metric: 0.1647\n",
      "Epoch 65/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4388 - custom_metric: 0.5232 - val_loss: 0.8280 - val_custom_metric: 0.1480\n",
      "Epoch 66/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.4286 - custom_metric: 0.5368 - val_loss: 0.8500 - val_custom_metric: 0.1527\n",
      "Epoch 67/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4275 - custom_metric: 0.5519 - val_loss: 0.8183 - val_custom_metric: 0.1695\n",
      "Epoch 68/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4181 - custom_metric: 0.5676 - val_loss: 0.8342 - val_custom_metric: 0.1838\n",
      "Epoch 69/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4175 - custom_metric: 0.5543 - val_loss: 0.8242 - val_custom_metric: 0.1862\n",
      "Epoch 70/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.4097 - custom_metric: 0.5790 - val_loss: 0.8224 - val_custom_metric: 0.1432\n",
      "Epoch 71/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3985 - custom_metric: 0.5904 - val_loss: 0.8241 - val_custom_metric: 0.1504\n",
      "Epoch 72/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3986 - custom_metric: 0.5965 - val_loss: 0.8320 - val_custom_metric: 0.1695\n",
      "Epoch 73/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3947 - custom_metric: 0.5936 - val_loss: 0.8719 - val_custom_metric: 0.1766\n",
      "Epoch 74/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3860 - custom_metric: 0.6138 - val_loss: 0.8776 - val_custom_metric: 0.1575\n",
      "Epoch 75/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3703 - custom_metric: 0.6371 - val_loss: 0.8593 - val_custom_metric: 0.1790\n",
      "Epoch 76/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3728 - custom_metric: 0.6315 - val_loss: 0.8694 - val_custom_metric: 0.1575\n",
      "Epoch 77/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.3756 - custom_metric: 0.6244 - val_loss: 0.8568 - val_custom_metric: 0.1527\n",
      "Epoch 78/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3666 - custom_metric: 0.6345 - val_loss: 0.8630 - val_custom_metric: 0.1742\n",
      "Epoch 79/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3661 - custom_metric: 0.6297 - val_loss: 0.8558 - val_custom_metric: 0.1695\n",
      "Epoch 80/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3552 - custom_metric: 0.6597 - val_loss: 0.8776 - val_custom_metric: 0.1647\n",
      "Epoch 81/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3600 - custom_metric: 0.6512 - val_loss: 0.9001 - val_custom_metric: 0.1504\n",
      "Epoch 82/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3499 - custom_metric: 0.6674 - val_loss: 0.9013 - val_custom_metric: 0.1695\n",
      "Epoch 83/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3474 - custom_metric: 0.6684 - val_loss: 0.9045 - val_custom_metric: 0.1456\n",
      "Epoch 84/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3408 - custom_metric: 0.6711 - val_loss: 0.9135 - val_custom_metric: 0.1575\n",
      "Epoch 85/500\n",
      "118/118 [==============================] - 10s 87ms/step - loss: 0.3357 - custom_metric: 0.6934 - val_loss: 0.8921 - val_custom_metric: 0.1742\n",
      "Epoch 86/500\n",
      "118/118 [==============================] - 10s 88ms/step - loss: 0.3346 - custom_metric: 0.6905 - val_loss: 0.8809 - val_custom_metric: 0.1933\n",
      "Epoch 87/500\n",
      "118/118 [==============================] - 11s 91ms/step - loss: 0.3341 - custom_metric: 0.6846 - val_loss: 0.9167 - val_custom_metric: 0.1623\n",
      "Epoch 88/500\n",
      " 46/118 [==========>...................] - ETA: 6s - loss: 0.3275 - custom_metric: 0.7004"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28520/2173425470.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# use the following for validation and training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# The following line is used for manual stopping of the network training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1214\u001b[0m                 _r=1):\n\u001b[0;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    940\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\myenv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=1e-5), metrics=[custom_metric])\n",
    "\n",
    "# use the following for validation and training\n",
    "history = model.fit(X_train, y_train, epochs=500,validation_data=(X_val, y_val))\n",
    "\n",
    "# The following line is used for manual stopping of the network training\n",
    "#history = model.fit(X_train, y_train, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f8b14",
   "metadata": {},
   "source": [
    "## Testing Stage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a1678af",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ea8f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert probabilities to class labels (one-hot encoding)\n",
    "y_pred[y_pred>=0.5] = 1\n",
    "y_pred[y_pred<0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c8c60b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3239795918367347"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# exact match rate \n",
    "# code used from https://medium.com/analytics-vidhya/metrics-for-multi-label-classification-49cc5aeba1c3\n",
    "# This function determines the rate of exact \n",
    "def emr(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    row_indicators = np.all(y_true == y_pred, axis = 1) \n",
    "    exact_match_count = np.sum(row_indicators)\n",
    "    return exact_match_count/n\n",
    "\n",
    "emr(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba2ca457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " animal_dogs       0.64      0.77      0.70       230\n",
      "animal_birds       0.74      0.73      0.74       229\n",
      "  background       0.43      0.30      0.36       105\n",
      "\n",
      "   micro avg       0.65      0.67      0.66       564\n",
      "   macro avg       0.60      0.60      0.60       564\n",
      "weighted avg       0.64      0.67      0.65       564\n",
      " samples avg       0.68      0.69      0.65       564\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andy\\anaconda3\\envs\\myenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=final_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f77d14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
